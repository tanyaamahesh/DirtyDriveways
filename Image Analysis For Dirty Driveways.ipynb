{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e308d-a310-4712-9df7-1ee70d64e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenCV libraries and parse arguments\n",
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    " \n",
    "# Construct the argument parser and parse the arguments\n",
    "# This will allow us to invoke the utility from the command line using the following format\n",
    "# python <code-file.py> -i <image-filename.png>\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", type=str, required=True, help=\"path to input image\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6d8401-bb30-4cfb-8bc7-0da2aadeea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img_rgb = cv2.imread(args[\"image\"], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b078e1-5d4b-475c-8d49-83c10404a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Image to grayscale\n",
    "image_gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa9af6c-8bce-4486-b97d-ddf895b84d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding the image\n",
    "# Convert very dark areas to black completely using OTSU Binarization, and lighter areas to white \n",
    "# Black = 0\n",
    "# White = 1\n",
    "# Automatically calculates the lowest and highest values of an image instead of developer provided thresholds\n",
    " \n",
    "ret,image_thresholded= cv2.threshold(image_gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "equalize= cv2.equalizeHist(image_thresholded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca13c92-81ee-43a7-8b56-b10882885921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Bitwise AND\n",
    "# The mask contains 2 values for each pixel\n",
    "# Black = 0\n",
    "# White = 1\n",
    "# The Bitwise AND operation retains the original pixel value when the value of the mask is 1, and converts the pixel value to black [0,0,0] where the mask is 0\n",
    "\n",
    "image_new = cv2.bitwise_and(image_rgb, image_rgb, mask = equalize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3febf-a3f0-4c3f-8895-380098119899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding the image\n",
    "# Convert very dark areas to black completely using OTSU Binarization, and lighter areas to white \n",
    "# Black = 0\n",
    "# White = 1\n",
    "# Automatically calculates the lowest and highest values of an image instead of developer provided thresholds\n",
    " \n",
    "ret,image_thresholded= cv2.threshold(image_gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "equalize= cv2.equalizeHist(image_thresholded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2280f8-f735-4bc7-8a38-0ababb69fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove noise - small sections that aren't blacked out yet, by using a sliding 5x5 rectangle\n",
    "# Before this step, all dark areas in the original image are fully black\n",
    "# Select only those pixel values that are not fully black\n",
    "lower_bound=np.array([1,0,0])\n",
    "upper_bound=np.array([255,255,255])\n",
    "mask=cv2.inRange(image_new, lower_bound, upper_bound)\n",
    "\n",
    "# Use a sliding 5x5 rectangle\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "image_new = cv2.bitwise_and(image_rgb, image_rgb, mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401d882d-9bec-455e-9231-44b2480574a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all contiguous black areas to transparent\n",
    "# Convert from BGR to BGRA (to add alpha/transparency channel)\n",
    "bgra = cv2.cvtColor(image_new, cv2.COLOR_BGR2BGRA)\n",
    "alpha = bgra[:, :, 3]\n",
    "\n",
    "# Use logical indexing to set alpha/transparency channel to 0 where BGR=0\n",
    "alpha[np.all(bgra[:, :, 0:3] == (0, 0, 0), 2)] = 0\n",
    "\n",
    "# Save bgra to PNG file\n",
    "cv2.imwrite('bgra.png', bgra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f7e29e-ea9c-49aa-8bb7-1512b1cee2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "# Arbitrary threshold selected by author to classify an image as clean or dirty\n",
    "# [RGB = (150,150,150)]\n",
    "# DirtyIndex = 0.15 or 15%\n",
    "# The closer the Dirty Index is to 0, the cleaner it is. Anything higher than 0.15 is classified as dirty\n",
    "LIGHT_MIN=np.array([150,150,150,255], np.uint8)\n",
    "LIGHT_MAX=np.array([255,255,255,255], np.uint8)\n",
    "dst=cv2.inRange(bgra, LIGHT_MIN, LIGHT_MAX)\n",
    "num_light=cv2.countNonZero(dst)\n",
    "print('The number of light pixels is: ' + str(num_light))\n",
    " \n",
    "DARK_MIN=np.array([0,0,0,255], np.uint8)\n",
    "DARK_MAX=np.array([149,149,149,255], np.uint8)\n",
    "dst=cv2.inRange(bgra, DARK_MIN, DARK_MAX)\n",
    "num_dark=cv2.countNonZero(dst)\n",
    "print('The number of dark pixels is: ' + str(num_dark))\n",
    " \n",
    "dirtyIndex = num_dark/(num_light + num_dark)\n",
    "print('Dirtiness index: ' + str(round(dirtyIndex, 2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
